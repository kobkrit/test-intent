{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `true-intent` Destination Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide 3 benchmarks for the 7-class multi-class classification of `destination` column in `truevoice-intnet` dataset: [fastText](https://github.com/facebookresearch/fastText), LinearSVC and [ULMFit](https://github.com/cstorm125/thai2fit). In the transfer learning cases, we first finetune the embeddings using all data. The test set contains 20% of all data split by [TrueVoice](http://www.truevoice.co.th/). The rest is split into 85/15 train-validation split randomly. Performance metrics are micro-averaged accuracy and F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| model     | accuracy | micro-F1 |\n",
    "|-----------|----------|----------|\n",
    "| fastText  | 0.384116 | 0.384116 |\n",
    "| LinearSVC | 0.807876 | 0.327565 |\n",
    "| **ULMFit**    | **0.834981**  | **0.834981** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pythainlp import word_tokenize\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "#viz\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def replace_newline(t):\n",
    "    return re.sub('[\\n]{1,}', ' ', t)\n",
    "\n",
    "ft_data = 'ft_data/'\n",
    "\n",
    "y = 'destination'\n",
    "nb_class = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import emoji\n",
    "\n",
    "def replace_url(text):\n",
    "    URL_PATTERN = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?¬´¬ª‚Äú‚Äù‚Äò‚Äô])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\"\n",
    "    return re.sub(URL_PATTERN, 'xxurl', text)\n",
    "\n",
    "def replace_rep(text):\n",
    "    def _replace_rep(m):\n",
    "        c,cc = m.groups()\n",
    "        return f'{c}xxrep'\n",
    "    re_rep = re.compile(r'(\\S)(\\1{2,})')\n",
    "    return re_rep.sub(_replace_rep, text)\n",
    "\n",
    "def ungroup_emoji(toks):\n",
    "    res = []\n",
    "    for tok in toks:\n",
    "        if emoji.emoji_count(tok) == len(tok):\n",
    "            for char in tok:\n",
    "                res.append(char)\n",
    "        else:\n",
    "            res.append(tok)\n",
    "    return res\n",
    "\n",
    "def process_text(text):\n",
    "    #pre rules\n",
    "    res = text.lower().strip()\n",
    "    res = replace_url(res)\n",
    "    res = replace_rep(res)\n",
    "    \n",
    "    #tokenize\n",
    "    res = [word for word in res.split('|') if word and not re.search(pattern=r\"\\s+\", string=word)]\n",
    "    \n",
    "    #post rules\n",
    "    res = ungroup_emoji(res)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.3'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(emoji)\n",
    "emoji.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ']\n"
     ]
    }
   ],
   "source": [
    "print(process_text(\"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ|https://google.com|555555555555|üòÇ|dddüòÇ| üòÇ| üòÇ| üòÇ| üòÇ| üòÇ| üòÇ| üòÇ| üòÇ| üòÇ| üòÇ\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-validation-test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform 85/15 train-validation split in addition to the test split by [TrueVoice](http://www.truevoice.co.th/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏±‡∏ï‡∏£‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û</td>\n",
       "      <td>user_ask_health_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏à‡πá‡∏ö‡∏õ‡πà‡∏ß‡∏¢</td>\n",
       "      <td>user_ask_health_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏±‡∏ï‡∏£</td>\n",
       "      <td>user_ask_health_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡∏Ç‡∏≠‡∏ö‡∏±‡∏ï‡∏£‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û</td>\n",
       "      <td>user_ask_health_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡∏Ç‡∏≠‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏à‡πá‡∏ö‡∏õ‡πà‡∏ß‡∏¢</td>\n",
       "      <td>user_ask_health_card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text                 class\n",
       "0    ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏±‡∏ï‡∏£‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û  user_ask_health_card\n",
       "1  ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏à‡πá‡∏ö‡∏õ‡πà‡∏ß‡∏¢  user_ask_health_card\n",
       "2          ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏±‡∏ï‡∏£  user_ask_health_card\n",
       "3      ‡∏Ç‡∏≠‡∏ö‡∏±‡∏ï‡∏£‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û  user_ask_health_card\n",
       "4    ‡∏Ç‡∏≠‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏à‡πá‡∏ö‡∏õ‡πà‡∏ß‡∏¢  user_ask_health_card"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "all_df = pd.read_csv(f'intents.csv')\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(all_df, test_size=0.15, random_state=1412)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(743, 2) (132, 2) (875, 2)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(f'intents.csv')\n",
    "print(train_df.shape, valid_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_ask_hospital_near_me             0.062857\n",
       "user_ask_followup                     0.054857\n",
       "user_ask_my_policy                    0.052571\n",
       "user_ask_max_how_to_register          0.051429\n",
       "user_ask_cancel                       0.046857\n",
       "user_ask_max_how_to_gain_point        0.037714\n",
       "user_ask_product_info                 0.035429\n",
       "user_ask_info_investment_ins          0.033143\n",
       "user_ask_info_edu_ins                 0.030857\n",
       "User_ask_received_SMS_HBD             0.030857\n",
       "user_ask_to_pay                       0.029714\n",
       "user_ask_max_how_to_redeem            0.026286\n",
       "user_ask_max_what_is                  0.026286\n",
       "user_ask_fax_receive                  0.025143\n",
       "user_ask_tax_cert                     0.024000\n",
       "user_ask_BMW                          0.022857\n",
       "user_ask_info_cancer_ins              0.022857\n",
       "user_ask_info_saving_ins              0.021714\n",
       "user_greeting                         0.020571\n",
       "user_ask_how_to_claim                 0.020571\n",
       "user_need_to_talk_callcenter          0.019429\n",
       "user_ask_unitlink                     0.019429\n",
       "user_ask_max_change_phone             0.018286\n",
       "user_ask_max_forgot_password          0.018286\n",
       "user_ask_info_compensation_ins        0.018286\n",
       "user_ask_GOT7                         0.018286\n",
       "user_ask_info_accidental_ins          0.018286\n",
       "user_ask_life_insurance               0.017143\n",
       "user_ask_info_retirement_ins          0.017143\n",
       "user_ask_max_point_expired_date       0.016000\n",
       "user_ask_max_issue                    0.014857\n",
       "user_ask_fwd_powerlink                0.013714\n",
       "user_ask_max_want_new_prize           0.013714\n",
       "user_ask_max_how_to_load              0.013714\n",
       "user_ask_how_change_creditcard        0.009143\n",
       "user_ask_how_to_claim_web             0.009143\n",
       "user_ask_how_change_address_tel       0.008000\n",
       "testchoices                           0.008000\n",
       "user_ask_info_health_ins              0.008000\n",
       "user_ask_health_card                  0.006857\n",
       "location                              0.006857\n",
       "user_ask_what_can_bot_do              0.006857\n",
       "user_ask_how_change_name              0.004571\n",
       "user_ask_where_to_submit_documents    0.004571\n",
       "test_quick_reply                      0.003429\n",
       "user_ask_how_change_payment           0.003429\n",
       "give_rating                           0.002286\n",
       "user_ask_services                     0.002286\n",
       "user_say_chat_with_us                 0.001143\n",
       "MoreInfo                              0.001143\n",
       "new_entity_1981                       0.001143\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test set prevalence\n",
    "test_df['class'].value_counts() / test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ULMFit](https://github.com/cstorm125/thai2fit) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "#viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import CSVLogger, SaveModelCallback\n",
    "\n",
    "from pythainlp.ulmfit import *\n",
    "import pythainlp\n",
    "\n",
    "model_path = 'truevoice_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BaseTokenizer',\n",
       " 'List',\n",
       " 'TK_REP',\n",
       " 'ThaiTokenizer',\n",
       " '_ITOS_NAME_LSTM',\n",
       " '_MODEL_NAME_LSTM',\n",
       " '_THWIKI_LSTM',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_get_path',\n",
       " '_tokenizer',\n",
       " 'collections',\n",
       " 'device',\n",
       " 'document_vector',\n",
       " 'download',\n",
       " 'emoji',\n",
       " 'fix_html',\n",
       " 'get_corpus_path',\n",
       " 'lowercase_all',\n",
       " 'merge_wgts',\n",
       " 'normalize_char_order',\n",
       " 'np',\n",
       " 'post_rules_th',\n",
       " 'pre_rules_th',\n",
       " 're',\n",
       " 'replace_all_caps',\n",
       " 'replace_rep_after',\n",
       " 'rm_brackets',\n",
       " 'rm_useless_newlines',\n",
       " 'rm_useless_spaces',\n",
       " 'spec_add_spaces',\n",
       " 'torch',\n",
       " 'ungroup_emoji',\n",
       " 'word_tokenize']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pythainlp.ulmfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([all_df,test_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = Tokenizer(tok_func = ThaiTokenizer, lang = 'th', pre_rules = pre_rules_th, post_rules=post_rules_th)\n",
    "processor = [TokenizeProcessor(tokenizer=tt, chunksize=10000, mark_fields=False),\n",
    "            NumericalizeProcessor(vocab=None, max_vocab=60000, min_freq=3)]\n",
    "\n",
    "data_lm = (TextList.from_df(all_df, model_path, cols=['text'], processor=processor)\n",
    "    .random_split_by_pct(valid_pct = 0.01, seed = 1412)\n",
    "    .label_for_lm()\n",
    "    .databunch(bs=64))\n",
    "data_lm.sanity_check()\n",
    "data_lm.save('truevoice_lm.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_lm = load_data(model_path,'truevoice_lm.pkl')\n",
    "data_lm.sanity_check()\n",
    "len(data_lm.train_ds), len(data_lm.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>‡∏≠‡∏¢‡∏≤‡∏Å ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏° ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô ‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û xxbos   ‡∏≠‡∏¢‡∏≤‡∏Å ‡∏ñ‡∏≤‡∏° ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô ‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û xxbos   ‡∏°‡∏µ ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô ‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û ‡πÑ‡∏´‡∏° xxbos   ‡∏Ç‡∏≠ ‡∏î‡∏π ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô ‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û ‡∏´‡∏ô‡πà‡∏≠‡∏¢ xxbos   ‡∏Å‡∏£‡∏°‡∏ò‡∏£‡∏£‡∏°‡πå ‡∏≠‡∏∞‡πÑ‡∏£ ‡∏ö‡πâ‡∏≤‡∏á xxbos   ‡∏Å‡∏µ‡πà ‡∏Å‡∏£‡∏°‡∏ò‡∏£‡∏£‡∏°‡πå xxbos   ‡∏ï‡πâ‡∏≠‡∏á ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà xxbos   ‡∏ï‡πâ‡∏≠‡∏á ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ ‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà xxbos   ‡∏ñ‡∏∂‡∏á   xxunk   ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà xxbos   ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏° ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏£ xxbos   ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ ‡∏ß‡∏±‡∏ô ‡πÑ‡∏´‡∏ô xxbos   ‡∏ï‡πâ‡∏≠‡∏á ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ ‡∏ß‡∏±‡∏ô ‡πÑ‡∏´‡∏ô xxbos   ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ ‡∏ß‡∏±‡∏ô ‡∏≠‡∏∞‡πÑ‡∏£ xxbos   ‡∏ï‡πâ‡∏≠‡∏á ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ ‡∏ß‡∏±‡∏ô ‡∏≠‡∏∞‡πÑ‡∏£ xxbos   ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£ xxbos   ‡∏ï‡πâ‡∏≠‡∏á ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£ xxbos   ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ ‡∏°‡∏∞ ‡πÑ‡∏´ ‡∏£‡πà xxbos   ‡∏ï‡πâ‡∏≠‡∏á ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ ‡∏°‡∏∞ ‡πÑ‡∏´ ‡∏£‡πà xxbos   ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ ‡∏°‡∏∞ xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>‡∏Ç‡∏≠ ‡πÉ‡∏ö ‡πÄ‡∏Ñ‡∏•‡∏° ‡∏†‡∏≤‡∏©‡∏µ xxbos   ‡∏î‡∏π ‡πÉ‡∏ö ‡∏•‡∏î‡∏´‡∏¢‡πà‡∏≠‡∏ô xxbos   ‡∏Ç‡∏≠ ‡∏î‡∏π ‡πÉ‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à ‡∏´‡∏ô‡πà‡∏≠‡∏¢ xxbos   ‡∏Ç‡∏≠ ‡∏î‡∏π ‡πÉ‡∏ö‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏µ ‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡∏Ñ‡∏£‡∏±‡∏ö xxbos   ‡∏Ç‡∏≠ ‡πÉ‡∏ö xxunk ‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡∏†‡∏≤‡∏©‡∏µ ‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡∏Ñ‡πà‡∏∞ xxbos   ‡πÉ‡∏ö ‡∏•‡∏î‡∏´‡∏¢‡πà‡∏≠‡∏ô ‡∏†‡∏≤‡∏©‡∏µ xxunk ‡∏à‡∏≤‡∏Å ‡πÑ‡∏´ xxunk xxbos   ‡∏Ç‡∏≠ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏†‡∏≤‡∏©‡∏µ xxbos   ‡∏Ç‡∏≠ ‡πÉ‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à ‡∏´‡∏ô‡πà‡∏≠‡∏¢ xxbos   ‡∏Ç‡∏≠ ‡πÉ‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à ‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡∏™‡∏¥ xxbos   ‡∏à‡∏∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>‡πÄ‡∏á‡∏¥‡∏ô xxbos   ‡∏à‡∏∞ ‡∏à‡πà‡∏≤‡∏¢ ‡∏ï‡∏±‡∏á xxbos   ‡∏ñ‡∏∂‡∏á xxunk ‡∏ß ‡∏ó‡∏µ‡πà ‡∏ï‡πâ‡∏≠‡∏á ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏ö‡∏µ‡πâ‡∏¢‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô ‡πÅ‡∏•‡πâ‡∏ß   ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡∏à‡πà‡∏≤‡∏¢ ‡∏î‡πâ‡∏ß‡∏¢ ‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï ‡πÑ‡∏î‡πâ xxunk xxbos   ‡∏à‡∏∞ ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏ö‡∏µ‡πâ‡∏¢‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô ‡∏î‡πâ‡∏ß‡∏¢ ‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï ‡∏ï‡πâ‡∏≠‡∏á ‡∏à‡πà‡∏≤‡∏¢ ‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô xxbos   ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡∏Å‡∏≤‡∏£ ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏á‡∏¥‡∏ô xxbos   ‡∏Ñ‡πà‡∏≤ ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï ‡∏Ñ‡∏∞ xxbos   ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•   ‡∏≠‡∏¢‡∏π‡πà ‡πÉ‡∏ô ‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢ ‡∏°‡∏±‡πâ‡∏¢ xxbos   ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î   ‡∏°‡∏µ ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏• ‡πÉ‡∏ô ‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>xxbos   ‡∏°‡∏µ ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏• ‡πÑ‡∏´‡∏ô ‡∏ó‡∏µ‡πà ‡πÄ‡∏Ñ‡∏•‡∏° ‡πÅ‡∏ñ‡∏ß ‡∏ö‡πâ‡∏≤‡∏ô ‡πÑ‡∏î‡πâ ‡∏ö‡πâ‡∏≤‡∏á xxbos   ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ‡∏£‡∏û xxbos   ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏• ‡πÉ‡∏Å‡∏•‡πâ ‡πÜ xxbos   ‡∏≠‡∏¢‡∏≤‡∏Å ‡πÄ‡∏Ç‡πâ‡∏≤ ‡πÇ‡∏£‡∏á‡∏ö‡∏≤‡∏• xxbos   ‡∏≠‡∏¢‡∏≤‡∏Å ‡πÄ‡∏Ç‡πâ‡∏≤ ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏• xxbos   ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ‡∏£‡∏û. xxbos   ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤   ‡∏£‡∏û xxbos   ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤   ‡∏£‡∏û. xxbos   ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏• ‡πÉ‡∏Å‡∏•‡πâ ‡∏ï‡∏±‡∏ß ‡∏°‡∏µ ‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô ‡∏Ñ‡∏∞ xxbos   ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏• ‡πÉ‡∏Å‡∏•‡πâ ‡∏ï‡∏±‡∏ß</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(emb_sz=400, n_hid=1550, n_layers=4, pad_token=1, qrnn=False, tie_weights=True, out_bias=True,\n",
    "             output_p=0.25, hidden_p=0.1, input_p=0.2, embed_p=0.02, weight_p=0.15)\n",
    "trn_args = dict(drop_mult=0.9, clip=0.12, alpha=2, beta=1)\n",
    "\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, config=config, pretrained=False, **trn_args)\n",
    "\n",
    "#load pretrained models\n",
    "learn.load_pretrained(**_THWIKI_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='25', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      4.00% [1/25 01:53<45:25]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.027670</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='4', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/4 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(learn.data.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train frozen\n",
    "print('training frozen')\n",
    "learn.freeze_to(-1)\n",
    "learn.fit_one_cycle(1, 1e-3, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train unfrozen\n",
    "print('training unfrozen')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, 1e-4, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('truevoice_lm')\n",
    "learn.save_encoder('truevoice_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = Tokenizer(tok_func = ThaiTokenizer, lang = 'th', pre_rules = pre_rules_th, post_rules=post_rules_th)\n",
    "processor = [TokenizeProcessor(tokenizer=tt, chunksize=10000, mark_fields=False),\n",
    "            NumericalizeProcessor(vocab=data_lm.vocab, max_vocab=60000, min_freq=3)]\n",
    "\n",
    "train_df = pd.read_csv(f'mari_train.csv')\n",
    "train_df['destination'] = train_df.destination.map(lambda x: x.replace(' ','_'))\n",
    "\n",
    "data_cls = (TextList.from_df(train_df, model_path, cols=['texts'], processor=processor)\n",
    "    .random_split_by_pct(valid_pct = 0.05, seed = 1412)\n",
    "    .label_from_df('destination')\n",
    "    .add_test(TextList.from_df(test_df, model_path, cols=['texts'], processor=processor))\n",
    "    .databunch(bs=64)\n",
    "    )\n",
    "\n",
    "data_cls.sanity_check()\n",
    "data_cls.save('truevoice_cls.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(emb_sz=400, n_hid=1550, n_layers=4, pad_token=1, qrnn=False,\n",
    "             output_p=0.25, hidden_p=0.1, input_p=0.2, embed_p=0.02, weight_p=0.15)\n",
    "trn_args = dict(bptt=70, drop_mult=0.5, alpha=2, beta=1)\n",
    "\n",
    "learn = text_classifier_learner(data_cls, AWD_LSTM, config=config, pretrained=False, **trn_args)\n",
    "learn.opt_func = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "\n",
    "#load pretrained finetuned model\n",
    "learn.load_encoder('truevoice_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train unfrozen\n",
    "learn.freeze_to(-1)\n",
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradual unfreezing\n",
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2 / (2.6 ** 4), 1e-2), moms=(0.8, 0.7))\n",
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3 / (2.6 ** 4), 5e-3), moms=(0.8, 0.7))\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(3, slice(1e-3 / (2.6 ** 4), 1e-3), moms=(0.8, 0.7), \n",
    "                   callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', name='truevoice_cls')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, y_true = learn.get_preds(ds_type = DatasetType.Test, ordered=True)\n",
    "classes = learn.data.train_ds.classes\n",
    "y_true = np.array([classes[i] for i in y_true.numpy()])\n",
    "preds = np.array([classes[i] for i in probs.argmax(1).numpy()])\n",
    "prob = probs.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "enc_fit = enc.fit(test_df[y][:,None])\n",
    "pred_ohe = enc_fit.transform(preds[:,None]).toarray()\n",
    "y_ohe = enc_fit.transform(test_df[y][:,None]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#macro metrics\n",
    "for i in range(nb_class):\n",
    "    print(\n",
    "        (pred_ohe[:,i]==y_ohe[:,i]).mean(),\n",
    "        f1_score(pred_ohe[:,i],y_ohe[:,i]),\n",
    "        precision_score(pred_ohe[:,i],y_ohe[:,i]),\n",
    "        recall_score(pred_ohe[:,i],y_ohe[:,i])\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('micro metrics')\n",
    "(preds==test_df[y]).mean(), \\\n",
    "f1_score(test_df[y],preds,average='micro'), \\\n",
    "precision_score(test_df[y],preds,average='micro'), \\\n",
    "recall_score(test_df[y],preds,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
